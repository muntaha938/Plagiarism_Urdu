{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqt7OQYNw_wJ"
   },
   "source": [
    "**Importing Liabraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCuMhZsTxzRm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "llSNLnXzw_wL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.layers import InputSpec,Layer\n",
    "# from keras.engine import InputSpec, Layer\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
    "import os\n",
    "import pandas as pd\n",
    "import urduhack\n",
    "urduhack.download()\n",
    "from urduhack.models.lemmatizer import lemmatizer\n",
    "from urduhack.normalization import normalize\n",
    "from urduhack.preprocessing import normalize_whitespace, remove_punctuation,remove_accents,replace_numbers\n",
    "from urduhack.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sTgTUAoRw_wN"
   },
   "outputs": [],
   "source": [
    "# Custom Function for Stopwords Removal\n",
    "def remove_stopwords(text: str):\n",
    "    return \" \".join(word for word in text.split() if word not in STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yV5e_KzIw_wN"
   },
   "outputs": [],
   "source": [
    "# Custom Function For Applying Lemma\n",
    "def lemitizeStr(str):\n",
    "    lemme_str = \"\"\n",
    "    temp = lemmatizer.lemma_lookup(str)\n",
    "    for t in temp:\n",
    "        lemme_str += t[0] + \" \"\n",
    "    \n",
    "    return lemme_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV4CVJwxw_wO"
   },
   "source": [
    "# Preprocessing With Urdu Hack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WmQZTkBw_wO"
   },
   "source": [
    "**Text Preprocessing of Orignal Document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tF_KwfElyj62"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "id": "vF-cH1J8w_wO",
    "outputId": "0d43adaa-47ef-46d9-8f59-04a345781033"
   },
   "outputs": [],
   "source": [
    "original_file_read = pd.read_xml('./UPPC Corpus/data/001_task_a.xml',xpath=\"/UPPC_document\")\n",
    "original_file_data = original_file_read['UPPC_document'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2Fy-NGcdw_wP",
    "outputId": "1ad5198c-a666-4c7c-d277-dd59848f33c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "چودھری رحمت علی  16 نومبر1897  کو مشرقی پنجاب کے ضلع ہوشیار پور کے گائوں  موہراں میں ایک\n",
      " متوسط زمیندار جناب حاجی شاہ کے ہاں پیدا   ہوئے۔ ابتدائی تعلیم انہوں نے ایک مکتب سے حاصل کی جو ایک عالم دین چلا رہے تھے۔ میٹرک اینگلو سنسکرت ہائی اسکول جالندھر سے کیا۔ 1914  میں   مزید تعلیم کے لئے لاہور  تشریف  لائے انہوں نے اسلامیہ کالج لاہور میں داخلہ لیا۔ 1915 میں اسلامیہ کالج میں بزم  شبلی کی بنیاد رکھی کیونکہ وہ  مولاناشبلی سے بہت  متاثر تھے اور پھراس کے پلیٹ فارم  سے 1915 میں تقسیم  ہن کا نظریہ  پیش کیا۔ 1918 میں بی اے کرنے کے بعد جناب محمد  دین فوق کے اخبار کشمیر گزٹ میں اسسٹنٹ ایڈیٹر کی حیثیت سے اپنے کیئریر کا آغاز کیا۔ 1928 میں ایچی سن کالج میں اتالیق مقرر ہوئے۔ کچھ  عرصہ  بعد انگلستان تشریف لے گئے جہاں کیمبرج اور ڈبلن یونورسٹیوں سے قانون اور سیاست میں اعلیٰ ڈگریاں حاصل کیں۔ اس طرح 1933 میں انہوں نے برصغیر کے طلباء پر مشتمل ایک تنظیم پاکستان نیشنل لبریشن موومنٹ کے نام سے قائم کی۔ ذہن میں رکھئے گا 1933 میں۔اسی سال چودھری رحمت علی  نے دوسری گول می کانفرنس کے موقع  پر اپنا مشہور کتابچہ Now or Never اب یا کبھی نہیں۔ شائع کیا جس میں پہلی مرتبہ لفظ پاکستان استعمال کیا گیا۔ 1935 میں انہوں نے کیمبرج  سے ایک ہفت روزہ اخبار نکالا جس کا نام بھی پاکستان تھا۔ چودھری رحمت علی 23 مارچ کو آلانڈیا  مسلم لیگ کے چونتیسوی سالانہ اجلاس میں لاہور تشریف لانا چاہتے تھے لیکن چند روز قبل خاکساروں کی فائرنگ کی وجہ سے اس وقت کے وزیر اعلیٰ پنجاب جناب سکندر  حیات نے چودھری رحمت علی کے پنجاب میں داخلے پر پابندی عائد کر دی-29 جنوری 1951  کو وہ نمونیہ میں مبتلا ہو کر شدید بیماری کی حالت میں  انگلستان کے ایک مقامی نرسنگ ہوم میں داخل ہو گئے لیکن صحت یاب نہ ہو سکے اور 3 فروری 1951 کو اپنے خالق حقیقی سے جا ملی۔  چودھری رحمت  علی کا جسدخاکی انگلستان کے شہر کیمبرج کے قبرستان میں امانتاً  دفن  ہے۔\n",
      "1683\n"
     ]
    }
   ],
   "source": [
    "print(original_file_data)\n",
    "print(len(original_file_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3JDk-geTw_wQ"
   },
   "outputs": [],
   "source": [
    "# original_file_data = replace_numbers(original_file_data)\n",
    "original_file_data = normalize(original_file_data)\n",
    "original_file_data = remove_accents(original_file_data)\n",
    "original_file_data = remove_punctuation(original_file_data)\n",
    "original_file_data = normalize_whitespace(original_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BfLswGghw_wQ",
    "outputId": "a81b6be9-3a0a-4d74-d391-ab825f2f26d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "چودھری رحمت علی 16 نومبر1897 کو مشرقی پنجاب کے ضلع ہوشیار پور کے گائوں موہراں میں ایک\n",
      " متوسط زمیندار جناب حاجی شاہ کے ہاں پیدا ہوئے ابتدائی تعلیم انہوں نے ایک مکتب سے حاصل کی جو ایک عالم دین چلا رہے تھے میٹرک اینگلو سنسکرت ہائی اسکول جالندھر سے کیا 1914 میں مزید تعلیم کے لئے لاہور تشریف لائے انہوں نے اسلامیہ کالج لاہور میں داخلہ لیا 1915 میں اسلامیہ کالج میں بزم شبلی کی بنیاد رکھی کیونکہ وہ مولاناشبلی سے بہت متاثر تھے اور پھراس کے پلیٹ فارم سے 1915 میں تقسیم ہن کا نظریہ پیش کیا 1918 میں بی اے کرنے کے بعد جناب محمد دین فوق کے اخبار کشمیر گزٹ میں اسسٹنٹ ایڈیٹر کی حیثیت سے اپنے کیئریر کا آغاز کیا 1928 میں ایچی سن کالج میں اتالیق مقرر ہوئے کچھ عرصہ بعد انگلستان تشریف لے گئے جہاں کیمبرج اور ڈبلن یونورسٹیوں سے قانون اور سیاست میں اعلی ڈگریاں حاصل کیں اس طرح 1933 میں انہوں نے برصغیر کے طلباء پر مشتمل ایک تنظیم پاکستان نیشنل لبریشن موومنٹ کے نام سے قائم کی ذہن میں رکھئے گا 1933 میںاسی سال چودھری رحمت علی نے دوسری گول می کانفرنس کے موقع پر اپنا مشہور کتابچہ Now or Never اب یا کبھی نہیں شائع کیا جس میں پہلی مرتبہ لفظ پاکستان استعمال کیا گیا 1935 میں انہوں نے کیمبرج سے ایک ہفت روزہ اخبار نکالا جس کا نام بھی پاکستان تھا چودھری رحمت علی 23 مارچ کو آلانڈیا مسلم لیگ کے چونتیسوی سالانہ اجلاس میں لاہور تشریف لانا چاہتے تھے لیکن چند روز قبل خاکساروں کی فائرنگ کی وجہ سے اس وقت کے وزیر اعلی پنجاب جناب سکندر حیات نے چودھری رحمت علی کے پنجاب میں داخلے پر پابندی عائد کر دی29 جنوری 1951 کو وہ نمونیہ میں مبتلا ہو کر شدید بیماری کی حالت میں انگلستان کے ایک مقامی نرسنگ ہوم میں داخل ہو گئے لیکن صحت یاب نہ ہو سکے اور 3 فروری 1951 کو اپنے خالق حقیقی سے جا ملی چودھری رحمت علی کا جسدخاکی انگلستان کے شہر کیمبرج کے قبرستان میں امانتا دفن ہے\n",
      "1634\n"
     ]
    }
   ],
   "source": [
    "print(original_file_data)\n",
    "print(len(original_file_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QX2WZfdvw_wQ"
   },
   "outputs": [],
   "source": [
    "original_file_data = remove_stopwords(original_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MmWQIZjsw_wQ",
    "outputId": "790aebeb-6b48-4073-85fc-afc2f69424b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "چودھری رحمت علی 16 نومبر1897 مشرقی پنجاب ضلع ہوشیار پور گائوں موہراں متوسط زمیندار حاجی شاہ پیدا ابتدائی تعلیم مکتب حاصل عالم دین میٹرک اینگلو سنسکرت ہائی اسکول جالندھر 1914 تعلیم لاہور تشریف اسلامیہ کالج لاہور داخلہ 1915 اسلامیہ کالج بزم شبلی بنیاد مولاناشبلی متاثر پھراس پلیٹ فارم 1915 تقسیم ہن نظریہ پیش 1918 بی اے محمد دین فوق اخبار کشمیر گزٹ اسسٹنٹ ایڈیٹر حیثیت کیئریر آغاز 1928 ایچی سن کالج اتالیق مقرر عرصہ انگلستان تشریف کیمبرج ڈبلن یونورسٹیوں قانون سیاست اعلی ڈگریاں حاصل کیں 1933 برصغیر طلباء مشتمل تنظیم پاکستان نیشنل لبریشن موومنٹ نام قائم ذہن رکھئے 1933 میںاسی سال چودھری رحمت علی گول می کانفرنس موقع مشہور کتابچہ Now or Never شائع مرتبہ لفظ پاکستان استعمال 1935 کیمبرج ہفت روزہ اخبار نکالا نام پاکستان چودھری رحمت علی 23 مارچ آلانڈیا مسلم لیگ چونتیسوی سالانہ اجلاس لاہور تشریف روز خاکساروں فائرنگ وقت وزیر اعلی پنجاب سکندر حیات چودھری رحمت علی پنجاب داخلے پابندی عائد دی29 جنوری 1951 نمونیہ مبتلا شدید بیماری حالت انگلستان مقامی نرسنگ ہوم داخل صحت یاب سکے 3 فروری 1951 خالق حقیقی ملی چودھری رحمت علی جسدخاکی انگلستان شہر کیمبرج قبرستان امانتا دفن\n",
      "1060\n"
     ]
    }
   ],
   "source": [
    "print(original_file_data)\n",
    "print(len(original_file_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OBk4vv6rw_wR"
   },
   "outputs": [],
   "source": [
    "lemmatized = lemitizeStr(original_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OJ265QuAw_wR",
    "outputId": "8918036c-6906-4d6c-efc6-02f97a15a19f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'چودھری رحمت علی 16 نومبر1897 مشرقی پنجاب ضلع ہوشیار پور گائوں موہراں متوسط زمیندار حاجی شاہ پیدا ابتدائی تعلیم مکتب حاصل عالم دین میٹرک اینگلو سنسکرت ہائی اسکول جالندھر 1914 تعلیم لاہور تشریف اسلامیہ کالج لاہور داخلہ 1915 اسلامیہ کالج بزم شبلی بنیاد مولاناشبلی متاثر پھراس پلیٹ فارم 1915 تقسیم ہن نظریہ پیش 1918 بی اے محمد دین فوق اخبار کشمیر گزٹ اسسٹنٹ ایڈیٹر حیثیت کیئریر آغاز 1928 ایچی سن کالج اتالیق مقرر عرصہ انگلستان تشریف کیمبرج ڈبلن یونورسٹیوں قانون سیاست اعلی ڈگریاں حاصل کیں 1933 برصغیر طلباء مشتمل تنظیم پاکستان نیشنل لبریشن موومنٹ نام قائم ذہن رکھئے 1933 میںاسی سال چودھری رحمت علی گول می کانفرنس موقع مشہور کتابچہ Now or Never شائع مرتبہ لفظ پاکستان استعمال 1935 کیمبرج ہفت روزہ اخبار نکالا نام پاکستان چودھری رحمت علی 23 مارچ آلانڈیا مسلم لیگ چونتیسوی سالانہ اجلاس لاہور تشریف روز خاکساروں فائرنگ وقت وزیر اعلی پنجاب سکندر حیات چودھری رحمت علی پنجاب داخلے پابندی عائد دی29 جنوری 1951 نمونیہ مبتلا شدید بیماری حالت انگلستان مقامی نرسنگ ہوم داخل صحت یاب سکے 3 فروری 1951 خالق حقیقی ملی چودھری رحمت علی جسدخاکی انگلستان شہر کیمبرج قبرستان امانتا دفن '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "X_v84Z_hw_wR",
    "outputId": "82b80b2a-78b3-4e22-827d-2ba673c1da5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LrcXi0AGw_wS",
    "outputId": "f8c4b9ad-309c-4e69-a396-143491aac821"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "i7JS1yUhw_wS"
   },
   "outputs": [],
   "source": [
    "tokenizer_original = spacy.blank('ur')\n",
    "\n",
    "tokenized_original = tokenizer_original(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BHob-gjXw_wS",
    "outputId": "d1bbf167-91ad-4131-c943-7d8a4bf02012"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "چودھری رحمت علی 16 نومبر1897 مشرقی پنجاب ضلع ہوشیار پور گائوں موہراں متوسط زمیندار حاجی شاہ پیدا ابتدائی تعلیم مکتب حاصل عالم دین میٹرک اینگلو سنسکرت ہائی اسکول جالندھر 1914 تعلیم لاہور تشریف اسلامیہ کالج لاہور داخلہ 1915 اسلامیہ کالج بزم شبلی بنیاد مولاناشبلی متاثر پھراس پلیٹ فارم 1915 تقسیم ہن نظریہ پیش 1918 بی اے محمد دین فوق اخبار کشمیر گزٹ اسسٹنٹ ایڈیٹر حیثیت کیئریر آغاز 1928 ایچی سن کالج اتالیق مقرر عرصہ انگلستان تشریف کیمبرج ڈبلن یونورسٹیوں قانون سیاست اعلی ڈگریاں حاصل کیں 1933 برصغیر طلباء مشتمل تنظیم پاکستان نیشنل لبریشن موومنٹ نام قائم ذہن رکھئے 1933 میںاسی سال چودھری رحمت علی گول می کانفرنس موقع مشہور کتابچہ Now or Never شائع مرتبہ لفظ پاکستان استعمال 1935 کیمبرج ہفت روزہ اخبار نکالا نام پاکستان چودھری رحمت علی 23 مارچ آلانڈیا مسلم لیگ چونتیسوی سالانہ اجلاس لاہور تشریف روز خاکساروں فائرنگ وقت وزیر اعلی پنجاب سکندر حیات چودھری رحمت علی پنجاب داخلے پابندی عائد دی29 جنوری 1951 نمونیہ مبتلا شدید بیماری حالت انگلستان مقامی نرسنگ ہوم داخل صحت یاب سکے 3 فروری 1951 خالق حقیقی ملی چودھری رحمت علی جسدخاکی انگلستان شہر کیمبرج قبرستان امانتا دفن "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "glove_embeddings = {}\n",
    "with open(\"glove.840B.300d.txt\",encoding=\"utf8\") as f:\n",
    "\n",
    "    for line in f:\n",
    "\n",
    "        try:\n",
    "            line = line.split()\n",
    "            glove_embeddings[line[0]] = np.array(line[1:], dtype=np.float32)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m max_tokens \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m \u001b[39m## Hyperparameter\u001b[39;00m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[39m=\u001b[39m Tokenizer()\n\u001b[1;32m----> 7\u001b[0m tokenizer\u001b[39m.\u001b[39;49mfit_on_texts(tokenized_original)\n\u001b[0;32m      9\u001b[0m \u001b[39m## Vectorizing data to keep 50 words per sample.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_train_vect \u001b[39m=\u001b[39m pad_sequences(tokenizer\u001b[39m.\u001b[39mtexts_to_sequences(tokenized_original), maxlen\u001b[39m=\u001b[39mmax_tokens, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, truncating\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\text.py:293\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 293\u001b[0m         seq \u001b[39m=\u001b[39m text_to_word_sequence(\n\u001b[0;32m    294\u001b[0m             text,\n\u001b[0;32m    295\u001b[0m             filters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilters,\n\u001b[0;32m    296\u001b[0m             lower\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower,\n\u001b[0;32m    297\u001b[0m             split\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit,\n\u001b[0;32m    298\u001b[0m         )\n\u001b[0;32m    299\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    300\u001b[0m         seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer(text)\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\text.py:74\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Converts a text to a sequence of words (or tokens).\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[39mDeprecated: `tf.keras.preprocessing.text.text_to_word_sequence` does not\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39m    A list of words (or tokens).\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> 74\u001b[0m     input_text \u001b[39m=\u001b[39m input_text\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     76\u001b[0m translate_dict \u001b[39m=\u001b[39m {c: split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m filters}\n\u001b[0;32m     77\u001b[0m translate_map \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_tokens = 50 ## Hyperparameter\n",
    "\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(tokenized_original)\n",
    "\n",
    "## Vectorizing data to keep 50 words per sample.\n",
    "X_train_vect = pad_sequences(tokenizer.texts_to_sequences(tokenized_original), maxlen=max_tokens, padding=\"post\", truncating=\"post\", value=0.)\n",
    "# X_test_vect  = pad_sequences(tokenizer.texts_to_sequences(X_test_text), maxlen=max_tokens, padding=\"post\", truncating=\"post\", value=0.)\n",
    "\n",
    "print(X_train_vect[:3])\n",
    "\n",
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"D:\\\\NLP Task\\\\glove.840B.300d.txt\"\n",
    "embed_size = 300\n",
    "max_features = 30000\n",
    "\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lx-TMTwpw_wS",
    "outputId": "d0216c88-b544-44cd-bc74-741cf329e5ce"
   },
   "outputs": [],
   "source": [
    "# doc = TfidfVectorizer(preprocessor=callable).fit_transform(tokenized_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPCi0B6Bw_wT"
   },
   "source": [
    "**Text Preprocessing of NP Document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eIHGMBMvw_wT"
   },
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "Start tag expected, '<' not found, line 1, column 1 (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3378\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn [20], line 1\u001b[0m\n    pnp_file_read = pd.read_xml('./UPPC Corpus/data/086_task_a_np.xml',xpath=\"/UPPC_document\")\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m in \u001b[0;35mwrapper\u001b[0m\n    return func(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\xml.py:1088\u001b[0m in \u001b[0;35mread_xml\u001b[0m\n    return _parse(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\xml.py:827\u001b[0m in \u001b[0;35m_parse\u001b[0m\n    data_dicts = p.parse_data()\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\xml.py:551\u001b[0m in \u001b[0;35mparse_data\u001b[0m\n    self.xml_doc = self._parse_doc(self.path_or_buffer)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\xml.py:636\u001b[0m in \u001b[0;35m_parse_doc\u001b[0m\n    doc = fromstring(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\lxml\\etree.pyx:3254\u001b[0m in \u001b[0;35mlxml.etree.fromstring\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\lxml\\parser.pxi:1913\u001b[0m in \u001b[0;35mlxml.etree._parseMemoryDocument\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\lxml\\parser.pxi:1800\u001b[0m in \u001b[0;35mlxml.etree._parseDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\lxml\\parser.pxi:1141\u001b[0m in \u001b[0;35mlxml.etree._BaseParser._parseDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\lxml\\parser.pxi:615\u001b[0m in \u001b[0;35mlxml.etree._ParserContext._handleParseResultDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32msrc\\lxml\\parser.pxi:725\u001b[0m in \u001b[0;35mlxml.etree._handleParseResult\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32msrc\\lxml\\parser.pxi:654\u001b[1;36m in \u001b[1;35mlxml.etree._raiseParseError\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>:1\u001b[1;36m\u001b[0m\n\u001b[1;31mXMLSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Start tag expected, '<' not found, line 1, column 1\n"
     ]
    }
   ],
   "source": [
    "pnp_file_read = pd.read_xml('./UPPC Corpus/data/086_task_a_np.xml',xpath=\"/UPPC_document\")\n",
    "pnp_file_data = pnp_file_read['UPPC_document'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UV0AHbR-w_wT",
    "outputId": "173fbb88-1728-4a3b-d482-e26d8304b2ca"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pnp_file_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(pnp_file_data)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(pnp_file_data))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pnp_file_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(pnp_file_data)\n",
    "print(len(pnp_file_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APsESalxw_wU"
   },
   "outputs": [],
   "source": [
    "pnp_file_data = replace_numbers(pnp_file_data)\n",
    "pnp_file_data = normalize(pnp_file_data)\n",
    "pnp_file_data = remove_accents(pnp_file_data)\n",
    "pnp_file_data = remove_punctuation(pnp_file_data)\n",
    "pnp_file_data = normalize_whitespace(pnp_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eBvht_dPw_wU",
    "outputId": "2117d8da-d948-47d9-beca-035c040a2250"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pnp_file_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(pnp_file_data)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(pnp_file_data))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pnp_file_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(pnp_file_data)\n",
    "print(len(pnp_file_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WPyOIjKcw_wU"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pnp_file_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pnp_file_data \u001b[39m=\u001b[39m remove_stopwords(pnp_file_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pnp_file_data' is not defined"
     ]
    }
   ],
   "source": [
    "pnp_file_data = remove_stopwords(pnp_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1L2r4weWw_wV",
    "outputId": "c12b2039-23fa-4fb3-eeb5-e99a7bbe1eed"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pnp_file_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(pnp_file_data)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(pnp_file_data))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pnp_file_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(pnp_file_data)\n",
    "print(len(pnp_file_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LefdoIFBw_wV"
   },
   "outputs": [],
   "source": [
    "lemmatized = lemitizeStr(pnp_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tzWkXmVrw_wV",
    "outputId": "ce60561e-cd4e-4f58-a5b7-19436d4fb0fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'چودھری رحمت علی 16 نومبر1897 مشرقی پنجاب ضلع ہوشیار پور گائوں موہراں متوسط زمیندار حاجی شاہ پیدا ابتدائی تعلیم مکتب حاصل عالم دین میٹرک اینگلو سنسکرت ہائی اسکول جالندھر 1914 تعلیم لاہور تشریف اسلامیہ کالج لاہور داخلہ 1915 اسلامیہ کالج بزم شبلی بنیاد مولاناشبلی متاثر پھراس پلیٹ فارم 1915 تقسیم ہن نظریہ پیش 1918 بی اے محمد دین فوق اخبار کشمیر گزٹ اسسٹنٹ ایڈیٹر حیثیت کیئریر آغاز 1928 ایچی سن کالج اتالیق مقرر عرصہ انگلستان تشریف کیمبرج ڈبلن یونورسٹیوں قانون سیاست اعلی ڈگریاں حاصل کیں 1933 برصغیر طلباء مشتمل تنظیم پاکستان نیشنل لبریشن موومنٹ نام قائم ذہن رکھئے 1933 میںاسی سال چودھری رحمت علی گول می کانفرنس موقع مشہور کتابچہ Now or Never شائع مرتبہ لفظ پاکستان استعمال 1935 کیمبرج ہفت روزہ اخبار نکالا نام پاکستان چودھری رحمت علی 23 مارچ آلانڈیا مسلم لیگ چونتیسوی سالانہ اجلاس لاہور تشریف روز خاکساروں فائرنگ وقت وزیر اعلی پنجاب سکندر حیات چودھری رحمت علی پنجاب داخلے پابندی عائد دی29 جنوری 1951 نمونیہ مبتلا شدید بیماری حالت انگلستان مقامی نرسنگ ہوم داخل صحت یاب سکے 3 فروری 1951 خالق حقیقی ملی چودھری رحمت علی جسدخاکی انگلستان شہر کیمبرج قبرستان امانتا دفن '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4HfPk9y-w_wV",
    "outputId": "f489bd83-fa00-4e98-f352-55577678115a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pnp_file_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mlen\u001b[39m(pnp_file_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pnp_file_data' is not defined"
     ]
    }
   ],
   "source": [
    "len(pnp_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "8P3tTAzRw_wV"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pnp_file_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m tokenizer_pnp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mblank(\u001b[39m'\u001b[39m\u001b[39mur\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m tokenized_pnp \u001b[39m=\u001b[39m tokenizer_pnp(pnp_file_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pnp_file_data' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer_pnp = spacy.blank('ur')\n",
    "\n",
    "tokenized_pnp = tokenizer_pnp(pnp_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXSGFq_Yw_wW",
    "outputId": "30f3cd8d-2918-4fbd-f996-83ad29c1efc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "چودھری"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_pnp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 962: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m max_features \u001b[39m=\u001b[39m \u001b[39m30000\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_coefs\u001b[39m(word,\u001b[39m*\u001b[39marr): \u001b[39mreturn\u001b[39;00m word, np\u001b[39m.\u001b[39masarray(arr, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m embedding_index \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39;49m(get_coefs(\u001b[39m*\u001b[39;49mo\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m)) \u001b[39mfor\u001b[39;49;00m o \u001b[39min\u001b[39;49;00m \u001b[39mopen\u001b[39;49m(embedding_path))\n",
      "Cell \u001b[1;32mIn [31], line 6\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m max_features \u001b[39m=\u001b[39m \u001b[39m30000\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_coefs\u001b[39m(word,\u001b[39m*\u001b[39marr): \u001b[39mreturn\u001b[39;00m word, np\u001b[39m.\u001b[39masarray(arr, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m embedding_index \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(get_coefs(\u001b[39m*\u001b[39mo\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39mopen\u001b[39m(embedding_path))\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_decode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 962: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "embedding_path = \"D:\\\\NLP Task\\\\glove.840B.300d.txt\"\n",
    "embed_size = 300\n",
    "max_features = 30000\n",
    "\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No text files found in directory D:\\NLP Task\\UPPC Corpus\\data\\Train. Allowed format: .txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m train_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mNLP Task\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUPPC Corpus\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdata\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mTrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m train_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mtext_dataset_from_directory(\n\u001b[0;32m      7\u001b[0m     train_dir, label_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m, labels\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minferred\u001b[39;49m\u001b[39m'\u001b[39;49m, follow_links \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m test_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mNLP Task\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUPPC Corpus\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdata\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mTest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m test_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mtext_dataset_from_directory(\n\u001b[0;32m     11\u001b[0m     test_dir, label_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minferred\u001b[39m\u001b[39m'\u001b[39m, follow_links \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\text_dataset.py:236\u001b[0m, in \u001b[0;36mtext_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, batch_size, max_length, shuffle, seed, validation_split, subset, follow_links)\u001b[0m\n\u001b[0;32m    232\u001b[0m file_paths, labels \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39mget_training_or_validation_split(\n\u001b[0;32m    233\u001b[0m     file_paths, labels, validation_split, subset\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m file_paths:\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo text files found in directory \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAllowed format: .txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m     )\n\u001b[0;32m    240\u001b[0m dataset \u001b[39m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[0;32m    241\u001b[0m     file_paths\u001b[39m=\u001b[39mfile_paths,\n\u001b[0;32m    242\u001b[0m     labels\u001b[39m=\u001b[39mlabels,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    245\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m    246\u001b[0m )\n\u001b[0;32m    247\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "\u001b[1;31mValueError\u001b[0m: No text files found in directory D:\\NLP Task\\UPPC Corpus\\data\\Train. Allowed format: .txt"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_dir = os.path.join('D:\\\\NLP Task\\\\UPPC Corpus\\\\data\\\\Train')\n",
    "train_dataset = tf.keras.utils_dataset_from_directory(\n",
    "    train_dir, label_mode='int', labels='inferred', follow_links = True\n",
    ")\n",
    "test_dir = os.path.join('D:\\\\NLP Task\\\\UPPC Corpus\\\\data\\\\Test')\n",
    "test_dataset = tf.keras.utils.text_dataset_from_directory(\n",
    "    test_dir, label_mode='int', labels='inferred', follow_links = True\n",
    ")\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "# Building the Recurrent Neural Network\n",
    "# using GRU cells and Hyperbolic tangent as activation function\n",
    "cell = tf.keras.layers.GRUCell(30, recurrent_activation='tanh')\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.RNN(cell)),\n",
    "    tf.keras.layers.Dense(60, activation='tanh'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "# Compile model and use the algorithm Adam as optimization function\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(1e-2), metrics=['accuracy'])\n",
    "# Fitting the model\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset, validation_steps=10)\n",
    "# Model Evaluation\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)\n",
    "# Visualize Model Loss and Accuracy\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7af7df4901773a0e355da496bf365ae011b1b331a57bbc9908dae1ee21823d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
